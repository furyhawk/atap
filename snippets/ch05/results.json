{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, stri...\n                 TruncatedSVD(algorithm='randomized', n_components=10000,\n                              n_iter=5, random_state=None, tol=0.0)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression (TruncatedSVD)", "accuracy": [0.648, 0.704, 0.68, 0.7016129032258065, 0.6693548387096774], "precision": [0.8004156766687079, 0.7306167693744164, 0.7075583333333334, 0.8299438990182328, 0.8319586999022484], "recall": [0.648, 0.704, 0.68, 0.7016129032258065, 0.6693548387096774], "f1": [0.5988554214385393, 0.6780786625800936, 0.6628819365807735, 0.697839123242349, 0.6522246613848849], "time": [70.35733699798584, 54.99729919433594, 40.79754877090454, 40.549619913101196, 44.250840187072754]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, stri...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x0000021E2996EB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression", "accuracy": [0.68, 0.64, 0.664, 0.7016129032258065, 0.6774193548387096], "precision": [0.77155310607607, 0.7506461251167134, 0.7612121212121211, 0.6934459805427547, 0.7727283053157655], "recall": [0.68, 0.64, 0.664, 0.7016129032258065, 0.6774193548387096], "f1": [0.6399324185675982, 0.6172378398360049, 0.6656820512820513, 0.6689967183649015, 0.6662759453013618], "time": [2.50600528717041, 2.614034414291382, 1.9980435371398926, 1.937089204788208, 1.8390471935272217]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, stri...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier (TruncatedSVD)", "accuracy": [0.84, 0.712, 0.784, 0.8064516129032258, 0.7741935483870968], "precision": [0.8501588433353139, 0.793278382454853, 0.8164973166368514, 0.8274171918544289, 0.7878245994304901], "recall": [0.84, 0.712, 0.784, 0.8064516129032258, 0.7741935483870968], "f1": [0.83919058939338, 0.7169396055796056, 0.7800699120234603, 0.8104357844489808, 0.7742352348762956], "time": [39.674726486206055, 40.189197301864624, 39.97559452056885, 43.93774199485779, 42.67177104949951]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, stri...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier", "accuracy": [0.824, 0.8, 0.824, 0.8467741935483871, 0.8225806451612904], "precision": [0.8203039627039627, 0.8204108868365417, 0.8386998986259946, 0.8467497556207234, 0.8310353671059753], "recall": [0.824, 0.8, 0.824, 0.8467741935483871, 0.8225806451612904], "f1": [0.8194019519920405, 0.8001787848085721, 0.8253058612819546, 0.846273539284292, 0.8197475233523577], "time": [2.1335837841033936, 1.8589656352996826, 2.0450029373168945, 1.8410382270812988, 2.1910018920898438]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x0000021E2996EB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n         verbose=False)", "name": "MultinomialNB", "accuracy": [0.56, 0.52, 0.584, 0.5403225806451613, 0.5967741935483871], "precision": [0.6399101123595505, 0.7468571428571428, 0.5911906976744186, 0.6793222181949982, 0.6236051200300075], "recall": [0.56, 0.52, 0.584, 0.5403225806451613, 0.5967741935483871], "f1": [0.5141305054789679, 0.5029288301152708, 0.5194856462708547, 0.5028904144947244, 0.5279699488856617], "time": [2.4120516777038574, 1.6819946765899658, 1.7835183143615723, 1.761018991470337, 1.9790003299713135]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x0000021E2996EB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('reduction',\n                 TruncatedSVD(algorithm='randomized', n_components=10000,\n                              n_iter=5, random_state=None, tol=0.0)),\n                ('classifier', GaussianNB(priors=None, var_smoothing=1e-09))],\n         verbose=False)", "name": "GaussianNB (TruncatedSVD)", "accuracy": [0.312, 0.272, 0.296, 0.3064516129032258, 0.29838709677419356], "precision": [0.5287307692307693, 0.42843678160919535, 0.3091238095238095, 0.3314384540190992, 0.32760713156230237], "recall": [0.312, 0.272, 0.296, 0.3064516129032258, 0.29838709677419356], "f1": [0.2411717057136412, 0.22800999000999003, 0.2167922792279228, 0.2223875313678485, 0.21475379021958557], "time": [37.88127684593201, 39.38164258003235, 44.1977059841156, 44.600038051605225, 41.40752172470093]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, stri...\n                 TruncatedSVD(algorithm='randomized', n_components=10000,\n                              n_iter=5, random_state=None, tol=0.0)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression (TruncatedSVD)", "accuracy": [0.648, 0.624, 0.648, 0.8145161290322581, 0.6612903225806451], "precision": [0.6820281690140845, 0.7705299145299146, 0.7320316205533598, 0.8283956780684341, 0.6814548956099269], "recall": [0.648, 0.624, 0.648, 0.8145161290322581, 0.6612903225806451], "f1": [0.6119551155115512, 0.5980676683174543, 0.6283458745874587, 0.8063215860916616, 0.6232459254750795], "time": [34.093018531799316, 27.485942602157593, 34.37619209289551, 38.39046502113342, 59.50668668746948]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, stri...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x000002664C9EEB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression", "accuracy": [0.76, 0.592, 0.664, 0.6693548387096774, 0.717741935483871], "precision": [0.781804347826087, 0.7599517867753162, 0.7612356374807988, 0.6860674872665534, 0.7672259044462856], "recall": [0.76, 0.592, 0.664, 0.6693548387096774, 0.717741935483871], "f1": [0.7269432343234324, 0.5511006812202818, 0.662504237405107, 0.6366815553916295, 0.6898105245141765], "time": [2.3700766563415527, 1.9330618381500244, 1.7800490856170654, 1.8340349197387695, 1.8480031490325928]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, stri...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier (TruncatedSVD)", "accuracy": [0.8, 0.752, 0.712, 0.8064516129032258, 0.8709677419354839], "precision": [0.8513999999999999, 0.805879900744417, 0.7491346646185356, 0.8622008324661811, 0.8716597282515935], "recall": [0.8, 0.752, 0.712, 0.8064516129032258, 0.8709677419354839], "f1": [0.7953316608806562, 0.7533253132832081, 0.7184465135781275, 0.8107849508703399, 0.8698853194946634], "time": [34.89279913902283, 33.16312313079834, 32.72082328796387, 38.03876328468323, 54.27425956726074]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, stri...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier", "accuracy": [0.856, 0.848, 0.784, 0.782258064516129, 0.8467741935483871], "precision": [0.8628151067323481, 0.859724482924483, 0.808315530090252, 0.7889172874543645, 0.8462819438625891], "recall": [0.856, 0.848, 0.784, 0.782258064516129, 0.8467741935483871], "f1": [0.8575474525474525, 0.8470535885264097, 0.7861172329104461, 0.7769937642563411, 0.8447806050891605], "time": [2.2310495376586914, 1.8156425952911377, 1.8320038318634033, 1.7979953289031982, 1.8540337085723877]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x000002664C9EEB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n         verbose=False)", "name": "MultinomialNB", "accuracy": [0.584, 0.552, 0.624, 0.47580645161290325, 0.6451612903225806], "precision": [0.6819999999999999, 0.5818544246451223, 0.7089156626506024, 0.5661816269284713, 0.7882562508096904], "recall": [0.584, 0.552, 0.624, 0.47580645161290325, 0.6451612903225806], "f1": [0.5399649673634636, 0.4949282099266005, 0.5678549679383947, 0.4148802598776158, 0.6099311350926325], "time": [1.9620614051818848, 1.9046502113342285, 1.7700598239898682, 1.7470014095306396, 1.804018259048462]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x000002664C9EEB88>,\n                                 use_idf=True, vocabulary=None)),\n                ('reduction',\n                 TruncatedSVD(algorithm='randomized', n_components=10000,\n                              n_iter=5, random_state=None, tol=0.0)),\n                ('classifier', GaussianNB(priors=None, var_smoothing=1e-09))],\n         verbose=False)", "name": "GaussianNB (TruncatedSVD)", "accuracy": [0.32, 0.416, 0.296, 0.31451612903225806, 0.3064516129032258], "precision": [0.3987906976744186, 0.4915186440677966, 0.3099954233409611, 0.7986844061245726, 0.3414330224916867], "recall": [0.32, 0.416, 0.296, 0.31451612903225806, 0.3064516129032258], "f1": [0.2473324595893403, 0.3072376230185561, 0.20492578616352203, 0.28791384137683945, 0.20015865206354638], "time": [38.80320906639099, 39.308310985565186, 49.7719292640686, 51.6150221824646, 40.441681146621704]}
